{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9bc8f370-7f7e-4a14-b46f-4d6675777a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Describe your app:  an application to track customer feedback\n",
      "Which model to use? (default: gpt-4o-mini):  anthropic/claude-sonnet-4-5-20250929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing app idea: an application to track customer feedback\n",
      "18.13s | 1498 tokens | $0.00449\n",
      "Schema plan:\n",
      " # Database Schema for Customer Feedback Tracking Application\n",
      "\n",
      "## Entities, Fields, and Relationships\n",
      "\n",
      "### 1. **Customer**\n",
      "Stores information about customers who provide feedback.\n",
      "\n",
      "**Fields:**\n",
      "- `id` (Integer, Primary Key, Auto-increment)\n",
      "- `email` (String, Unique, Indexed, Required)\n",
      "- `first_name` (String, Required)\n",
      "- `last_name` (String, Required)\n",
      "- `company` (String, Optional)\n",
      "- `phone` (String, Optional)\n",
      "- `created_at` (DateTime, Auto-generated)\n",
      "- `updated_at` (DateTime, Auto-updated)\n",
      "\n",
      "### 2. **Product**\n",
      "Represents products or services that customers provide feedback about.\n",
      "\n",
      "**Fields:**\n",
      "- `id` (Integer, Primary Key, Auto-increment)\n",
      "- `name` (String, Unique, Required)\n",
      "- `description` (Text, Optional)\n",
      "- `category` (String, Optional)\n",
      "- `is_active` (Boolean, Default: True)\n",
      "- `created_at` (DateTime, Auto-generated)\n",
      "- `updated_at` (DateTime, Auto-updated)\n",
      "\n",
      "### 3. **Feedback**\n",
      "Main entity for storing customer feedback submissions.\n",
      "\n",
      "**Fields:**\n",
      "- `id` (Integer, Primary Key, Auto-increment)\n",
      "- `customer_id` (Integer, Foreign Key → Customer.id, Required)\n",
      "- `product_id` (Integer, Foreign Key → Product.id, Optional)\n",
      "- `rating` (Integer, Required, Range: 1-5)\n",
      "- `title` (String, Required)\n",
      "- `description` (Text, Required)\n",
      "- `feedback_type` (Enum: 'bug', 'feature_request', 'complaint', 'praise', 'suggestion', Required)\n",
      "- `status` (Enum: 'new', 'in_review', 'planned', 'in_progress', 'resolved', 'closed', Default: 'new')\n",
      "- `priority` (Enum: 'low', 'medium', 'high', 'critical', Default: 'medium')\n",
      "- `source` (Enum: 'web', 'email', 'phone', 'social_media', 'in_app', Default: 'web')\n",
      "- `created_at` (DateTime, Auto-generated)\n",
      "- `updated_at` (DateTime, Auto-updated)\n",
      "\n",
      "### 4. **Comment**\n",
      "Allows internal team members or customers to add follow-up comments on feedback.\n",
      "\n",
      "**Fields:**\n",
      "- `id` (Integer, Primary Key, Auto-increment)\n",
      "- `feedback_id` (Integer, Foreign Key → Feedback.id, Required)\n",
      "- `user_id` (Integer, Foreign Key → User.id, Optional)\n",
      "- `comment_text` (Text, Required)\n",
      "- `is_internal` (Boolean, Default: False) - Internal notes vs customer-visible\n",
      "- `created_at` (DateTime, Auto-generated)\n",
      "- `updated_at` (DateTime, Auto-updated)\n",
      "\n",
      "### 5. **User**\n",
      "Internal staff members who manage and respond to feedback.\n",
      "\n",
      "**Fields:**\n",
      "- `id` (Integer, Primary Key, Auto-increment)\n",
      "- `email` (String, Unique, Required)\n",
      "- `username` (String, Unique, Required)\n",
      "- `hashed_password` (String, Required)\n",
      "- `full_name` (String, Required)\n",
      "- `role` (Enum: 'admin', 'manager', 'agent', Default: 'agent')\n",
      "- `is_active` (Boolean, Default: True)\n",
      "- `created_at` (DateTime, Auto-generated)\n",
      "- `updated_at` (DateTime, Auto-updated)\n",
      "\n",
      "### 6. **Tag**\n",
      "Categorization labels for feedback items.\n",
      "\n",
      "**Fields:**\n",
      "- `id` (Integer, Primary Key, Auto-increment)\n",
      "- `name` (String, Unique, Required)\n",
      "- `color` (String, Optional) - Hex color code for UI display\n",
      "- `created_at` (DateTime, Auto-generated)\n",
      "\n",
      "### 7. **FeedbackTag** (Association Table)\n",
      "Many-to-many relationship between Feedback and Tag.\n",
      "\n",
      "**Fields:**\n",
      "- `feedback_id` (Integer, Foreign Key → Feedback.id, Primary Key)\n",
      "- `tag_id` (Integer, Foreign Key → Tag.id, Primary Key)\n",
      "- `created_at` (DateTime, Auto-generated)\n",
      "\n",
      "### 8. **Attachment**\n",
      "Files attached to feedback (screenshots, documents, etc.).\n",
      "\n",
      "**Fields:**\n",
      "- `id` (Integer, Primary Key, Auto-increment)\n",
      "- `feedback_id` (Integer, Foreign Key → Feedback.id, Required)\n",
      "- `file_name` (String, Required)\n",
      "- `file_path` (String, Required)\n",
      "- `file_type` (String, Required)\n",
      "- `file_size` (Integer, Required) - in bytes\n",
      "- `created_at` (DateTime, Auto-generated)\n",
      "\n",
      "## Relationships\n",
      "\n",
      "1. **Customer → Feedback**: One-to-Many\n",
      "   - One customer can submit multiple feedback items\n",
      "\n",
      "2. **Product → Feedback**: One-to-Many\n",
      "   - One product can have multiple feedback items\n",
      "\n",
      "3. **Feedback → Comment**: One-to-Many\n",
      "   - One feedback item can have multiple comments\n",
      "\n",
      "4. **User → Comment**: One-to-Many\n",
      "   - One user can create multiple comments\n",
      "\n",
      "5. **Feedback ↔ Tag**: Many-to-Many (through FeedbackTag)\n",
      "   - One feedback item can have multiple tags\n",
      "   - One tag can be applied to multiple feedback items\n",
      "\n",
      "6. **Feedback → Attachment**: One-to-Many\n",
      "   - One feedback item can have multiple attachments\n",
      "\n",
      "## Indexes\n",
      "\n",
      "- `Customer.email` (Unique)\n",
      "- `Product.name` (Unique)\n",
      "- `Feedback.customer_id` (Foreign Key Index)\n",
      "- `Feedback.product_id` (Foreign Key Index)\n",
      "- `Feedback.status` (Query optimization)\n",
      "- `Feedback.created_at` (Query optimization)\n",
      "- `Comment.feedback_id` (Foreign Key Index)\n",
      "- `User.email` (Unique)\n",
      "- `User.username` (Unique)\n",
      "Generating SQLAlchemy schema...\n",
      "22.09s | 4151 tokens | $0.01245\n",
      "Saved generated/schema.py\n",
      "Generating FastAPI backend...\n",
      "API generated successfully with HTMX-compatible Form endpoints!\n",
      "Generating frontend app...\n",
      "24.16s | 2970 tokens | $0.00891\n",
      "Saved generated/frontend.py\n",
      "Generating index.html...\n",
      "36.14s | 4332 tokens | $0.01300\n",
      "Saved generated/templates/index.html\n",
      "\n",
      "================================================================\n",
      "RUN SUMMARY\n",
      "Model: anthropic/claude-sonnet-4-5-20250929\n",
      "Input Prompt: an application to track customer feedback\n",
      "Total tokens used: 12,951\n",
      "Estimated total cost: $0.03885\n",
      "Total runtime: 100.53 seconds\n",
      "Lines of code generated: 825\n",
      "==================================================================\n",
      "\n",
      "\n",
      "Execution Instructions:\n",
      "Run backend:  uvicorn generated.api:app --reload --port 8000\n",
      "Run frontend: uvicorn generated.frontend:app --reload --port 8001\n",
      "Then open http://127.0.0.1:8001 \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import time\n",
    "from sqlalchemy import inspect as sqlalchemy_inspect\n",
    "from litellm import completion\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# -------------------------------\n",
    "# Environment setup\n",
    "# -------------------------------\n",
    "load_dotenv()  # Loads all API keys from .env\n",
    "MODEL_PRICES = {\n",
    "    \"gpt-4o-mini\": {\"input\": 0.00000015, \"output\": 0.00000060},\n",
    "    \"gpt-5\": {\"input\": 0.00000125, \"output\": 0.00001000},\n",
    "    \"gpt-5-mini\": {\"input\": 0.00000025, \"output\": 0.00000200},\n",
    "    \"gpt-4-turbo\": {\"input\": 0.000010, \"output\": 0.000030},  \n",
    "    \"gpt-4.1\": {\"input\": 0.000005, \"output\": 0.000020},  # speculative\n",
    "    \"claude-3-opus\": {\"input\": 0.000015, \"output\": 0.000075},\n",
    "    \"claude-sonnet-4-5\": {\"input\": 0.000003, \"output\": 0.000015},  # ✅ new\n",
    "    \"deepseek-coder\": {\"input\": 0.00000010, \"output\": 0.00000010},\n",
    "    \"mistral-large\": {\"input\": 0.000004, \"output\": 0.000012},\n",
    "}\n",
    "\n",
    "# Global counters\n",
    "TOTAL_TOKENS = 0\n",
    "TOTAL_COST = 0.0\n",
    "TOTAL_START = time.time()\n",
    "\n",
    "def estimate_cost(model: str, prompt_tokens: int, completion_tokens: int) -> float:\n",
    "    \"\"\"\n",
    "    Estimate total USD cost of an LLM call.\n",
    "\n",
    "    Units:\n",
    "      - prompt_tokens: number of input tokens sent to the model\n",
    "      - completion_tokens: number of output tokens returned by the model\n",
    "      - rates: USD cost per token (input/output) for the given model\n",
    "      - returns: total estimated cost in USD (float)\n",
    "    \"\"\"\n",
    "    rates = MODEL_PRICES.get(model, {\"input\": 0.000003, \"output\": 0.000003})\n",
    "\n",
    "    input_cost = prompt_tokens * rates[\"input\"]\n",
    "    output_cost = completion_tokens * rates[\"output\"]\n",
    "    total_cost = input_cost + output_cost\n",
    "\n",
    "    # Round to 6 decimal places for readability and consistency\n",
    "    return round(total_cost, 6)\n",
    "# -------------------------------\n",
    "# Utility functions\n",
    "# -------------------------------\n",
    "def clean_code(text: str) -> str:\n",
    "    \"\"\"Remove markdown-style fences like ```python or ```html.\"\"\"\n",
    "    return re.sub(r\"```[a-zA-Z]*\\n?|```\", \"\", text).strip()\n",
    "\n",
    "def ask_model(model: str, prompt: str, temperature: float = 0.4):\n",
    "    \"\"\"\n",
    "    Unified interface for all LLM providers via LiteLLM.\n",
    "    Works with GPT, Claude, DeepSeek, Mistral, Ollama, etc.\n",
    "    Returns (response_text, latency_seconds, usage_dict)\n",
    "    \"\"\"\n",
    "\n",
    "    global TOTAL_TOKENS, TOTAL_COST\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    #Build the base kwargs\n",
    "    kwargs = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert FastAPI full-stack developer. Return only raw code, no markdown.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    if not any(m[\"role\"] == \"user\" for m in kwargs[\"messages\"]):\n",
    "        kwargs[\"messages\"].append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "    # Only include temperature if NOT GPT-5\n",
    "    if not model.lower().startswith(\"gpt-5\"):\n",
    "        kwargs[\"temperature\"] = temperature\n",
    "\n",
    "    try:\n",
    "        response = completion(**kwargs)\n",
    "    except TypeError:\n",
    "        # fallback if a model (like gpt-5) rejects 'temperature'\n",
    "        if \"temperature\" in kwargs:\n",
    "            del kwargs[\"temperature\"]\n",
    "        response = completion(**kwargs)\n",
    "\n",
    "    end = time.time()\n",
    "    latency = end - start\n",
    "\n",
    "    # Extract usage + cost\n",
    "    content = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "    usage = response.get(\"usage\", {})\n",
    "    prompt_tokens = usage.get(\"prompt_tokens\", 0)\n",
    "    completion_tokens = usage.get(\"completion_tokens\", 0)\n",
    "    total_tokens = prompt_tokens + completion_tokens\n",
    "    cost = estimate_cost(model, prompt_tokens, completion_tokens)\n",
    "    usage[\"cost_usd\"] = cost\n",
    "    usage[\"cost_usd\"] = cost\n",
    "\n",
    "    # Accumulate global totals\n",
    "    TOTAL_TOKENS += total_tokens\n",
    "    TOTAL_COST += cost\n",
    "\n",
    "    print(f\"{latency:.2f}s | {total_tokens} tokens | ${cost:.5f}\")\n",
    "    return clean_code(content), latency, usage\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Configurable model selector\n",
    "# -------------------------------\n",
    "DEFAULT_MODEL = \"gpt-4o-mini\"  # You can change this to claude-3-opus, deepseek-coder, etc.\n",
    "\n",
    "def ask(prompt: str, model: str = DEFAULT_MODEL):\n",
    "    \"\"\"Generic wrapper for app-building tasks.\"\"\"\n",
    "    #print(f\"\\nUsing model: {model}\")\n",
    "    response, latency, usage = ask_model(model, prompt)\n",
    "    #print(f\"Took {latency:.2f}s | Tokens: {usage.get('total_tokens', 'n/a')}\")\n",
    "    return response\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Step 1: Analyze app idea\n",
    "# -------------------------------\n",
    "def analyze_prompt(user_prompt: str, model: str = DEFAULT_MODEL) -> str:\n",
    "    print(f\"Analyzing app idea: {user_prompt}\")\n",
    "    analysis_prompt = f\"\"\"\n",
    "    The user wants a database-backed app.\n",
    "    Describe the entities, fields, and relationships.\n",
    "\n",
    "    User description:\n",
    "    {user_prompt}\n",
    "    \"\"\"\n",
    "    analysis = ask(analysis_prompt, model)\n",
    "    print(\"Schema plan:\\n\", analysis)\n",
    "    return analysis\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Step 2: Generate schema.py\n",
    "# -------------------------------\n",
    "def generate_schema(analysis: str, model: str = DEFAULT_MODEL):\n",
    "    print(\"Generating SQLAlchemy schema...\")\n",
    "    prompt = f\"\"\"\n",
    "    Write valid Python 3.11 code defining SQLAlchemy 2.0 ORM models using DeclarativeBase.\n",
    "\n",
    "    Requirements:\n",
    "    - Define class Base(DeclarativeBase)\n",
    "    - Each ORM class must subclass Base (e.g., `class Customer(Base):`) — do NOT use `Base()`\n",
    "    - Import from sqlalchemy.orm: DeclarativeBase, Mapped, mapped_column, relationship\n",
    "    - Import from sqlalchemy: Integer, String, Text, DateTime, ForeignKey, Column, Table\n",
    "    - Include __allow_unmapped__ = True in each class\n",
    "    - Each model must define a unique __tablename__\n",
    "    - Use mapped_column instead of Column *only inside ORM classes*\n",
    "    - When defining association tables with Table(), use Column() not mapped_column()\n",
    "    - When a table has multiple foreign keys to the same parent, specify `foreign_keys` explicitly in relationship()\n",
    "    - Avoid using reserved names like 'metadata', 'query', or 'registry'\n",
    "    - Use 'meta_data' instead of 'metadata'\n",
    "    - No markdown or explanations\n",
    "    - Only create models that are explicitly described in the user input\n",
    "    - Do NOT invent entities not mentioned in the description.\n",
    "    - If unsure, leave it out.\n",
    "    \n",
    "    Schema description:\n",
    "    {analysis}\n",
    "    \"\"\"\n",
    "    code = ask(prompt, model)\n",
    "    code = code = code.replace('(Base())', '(Base)')\n",
    "    Path(\"generated/schema.py\").write_text(code)\n",
    "    print(\"Saved generated/schema.py\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Step 3: Extract model names\n",
    "# -------------------------------\n",
    "def extract_model_names():\n",
    "    code = Path(\"generated/schema.py\").read_text()\n",
    "    return re.findall(r\"class\\s+(\\w+)\\s*\\(Base\\)\", code)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Step 4: Get model fields dynamically\n",
    "# -------------------------------\n",
    "def get_model_fields(model_name):\n",
    "    \"\"\"Return dict of model fields for dynamic Form() generation.\"\"\"\n",
    "    from generated import schema\n",
    "    model = getattr(schema, model_name)\n",
    "    mapper = sqlalchemy_inspect(model)\n",
    "    return {col.key: col.type.python_type.__name__ for col in mapper.columns if col.key != \"id\"}\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Step 5: Generate backend API\n",
    "# -------------------------------\n",
    "def generate_api():\n",
    "    \"\"\"\n",
    "    Generates a FastAPI backend (generated/api.py) with form-compatible endpoints.\n",
    "    Use valid Python 3.11 code.\n",
    "    This ensures HTMX forms (which send Form data) always match backend expectations.\n",
    "    \"\"\"\n",
    "    print(\"Generating FastAPI backend...\")\n",
    "\n",
    "    from generated import schema\n",
    "    import inspect, re\n",
    "    from pathlib import Path\n",
    "\n",
    "    # Dynamically extract model classes from schema\n",
    "    models = [\n",
    "        name for name, obj in inspect.getmembers(schema)\n",
    "        if inspect.isclass(obj) and hasattr(obj, \"__tablename__\")\n",
    "    ]\n",
    "\n",
    "    # Build safe import line\n",
    "    imports = \", \".join([\"Base\"] + models)\n",
    "\n",
    "    api_code = f\"\"\"from fastapi import FastAPI, HTTPException, Form, Depends\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from sqlalchemy.orm import Session, sessionmaker\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "try:\n",
    "    from .schema import {imports}\n",
    "except ImportError:\n",
    "    from .schema import Base\n",
    "\n",
    "SQLALCHEMY_DATABASE_URL = \"sqlite:///./test.db\"\n",
    "engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={{\"check_same_thread\": False}})\n",
    "SessionLocal = sessionmaker(bind=engine, autocommit=False, autoflush=False)\n",
    "\n",
    "def get_db():\n",
    "    db = SessionLocal()\n",
    "    try:\n",
    "        yield db\n",
    "    finally:\n",
    "        db.close()\n",
    "\n",
    "app = FastAPI(title=\"Generated API\", version=\"1.0\")\n",
    "\n",
    "# CORS for frontend\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"http://127.0.0.1:8001\", \"http://localhost:8001\", \"http://127.0.0.1\", \"http://localhost\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "Base.metadata.create_all(bind=engine)\n",
    "\"\"\"\n",
    "\n",
    "    # helper: convert CamelCase → snake_case\n",
    "    def snake_case(name):\n",
    "        return re.sub(r'(?<!^)(?=[A-Z])', '_', name).lower()\n",
    "\n",
    "    # generate CRUD routes\n",
    "    for model_name in models:\n",
    "        endpoint = snake_case(model_name)\n",
    "        api_code += f\"\"\"\n",
    "\n",
    "@app.post(\"/{endpoint}/\")\n",
    "async def create_{endpoint}(\n",
    "\"\"\"\n",
    "        # dynamically introspect model columns\n",
    "        model_cls = getattr(schema, model_name)\n",
    "        params = []\n",
    "        assignments = []\n",
    "        for col_name, col_type in model_cls.__annotations__.items():\n",
    "            if col_name == \"id\":\n",
    "                continue\n",
    "            # default all to Form(...) for HTMX compatibility\n",
    "            params.append(f\"    {col_name}: str = Form(...)\")\n",
    "            assignments.append(f\"{col_name}={col_name}\")\n",
    "\n",
    "        api_code += \",\\n\".join(params) + \",\\n    db: Session = Depends(get_db)\\n):\\n\"\n",
    "        api_code += f\"    new_item = {model_name}({', '.join(assignments)})\\n\"\n",
    "        api_code += \"    db.add(new_item)\\n    db.commit()\\n    db.refresh(new_item)\\n    return new_item\\n\"\n",
    "\n",
    "        # READ\n",
    "        api_code += f\"\"\"\n",
    "@app.get(\"/{endpoint}/\")\n",
    "async def read_{endpoint}s(db: Session = Depends(get_db)):\n",
    "    return db.query({model_name}).all()\n",
    "\"\"\"\n",
    "\n",
    "        # DELETE\n",
    "        api_code += f\"\"\"\n",
    "@app.delete(\"/{endpoint}/{{item_id}}\")\n",
    "async def delete_{endpoint}(item_id: int, db: Session = Depends(get_db)):\n",
    "    item = db.query({model_name}).filter({model_name}.id == item_id).first()\n",
    "    if not item:\n",
    "        raise HTTPException(status_code=404, detail=\"{model_name} not found\")\n",
    "    db.delete(item)\n",
    "    db.commit()\n",
    "    return {{\"message\": \"{model_name} deleted\"}}\n",
    "\"\"\"\n",
    "\n",
    "    Path(\"generated/api.py\").write_text(api_code)\n",
    "    print(\"API generated successfully with HTMX-compatible Form endpoints!\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Step 6: Generate frontend.py\n",
    "# -------------------------------\n",
    "def generate_frontend(models: list, model: str = DEFAULT_MODEL):\n",
    "    print(\"Generating frontend app...\")\n",
    "    model_imports = \", \".join(models)\n",
    "    prompt = f\"\"\"\n",
    "Write valid Python 3.11 code for a FastAPI app named 'app' that:\n",
    "- Imports Base, {model_imports} from .schema\n",
    "- Imports get_db from .api\n",
    "- Uses Jinja2Templates(\"./generated/templates\")\n",
    "- Renders index.html on '/'\n",
    "- Includes CRUD endpoints using Form() params and RedirectResponse\n",
    "- Does NOT use response_model or ORM types in function annotations\n",
    "- Returns RedirectResponse after POST and {{}} dicts for delete\n",
    "- All routes must include response_model=None in their decorators\n",
    "- No markdown fences\n",
    "\"\"\"\n",
    "    code = ask(prompt, model)\n",
    "    Path(\"generated/frontend.py\").write_text(code)\n",
    "    print(\"Saved generated/frontend.py\")\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Step 7: Generate index.html\n",
    "# -------------------------------\n",
    "# def generate_index_html(models: list, model: str = DEFAULT_MODEL):\n",
    "#     print(\"Generating index.html...\")\n",
    "#     Path(\"generated/templates\").mkdir(parents=True, exist_ok=True)\n",
    "#     prompt = f\"\"\"\n",
    "# Write a simple responsive Jinja2 HTML page using TailwindCSS and HTMX\n",
    "# for models {models}. It should:\n",
    "# - Display data tables and forms for each model\n",
    "# - Use hx-get, hx-post, and hx-delete for CRUD operations\n",
    "# - Target endpoints on http://127.0.0.1:8000\n",
    "# - Include a navbar and reload sections dynamically\n",
    "# - No markdown or code fences\n",
    "# \"\"\"\n",
    "#     html = ask(prompt, model)\n",
    "#     Path(\"generated/templates/index.html\").write_text(html)\n",
    "#     print(\"Saved generated/templates/index.html\")\n",
    "def generate_index_html(models: list, model: str = DEFAULT_MODEL):\n",
    "    print(\"Generating index.html...\")\n",
    "    Path(\"generated/templates\").mkdir(parents=True, exist_ok=True)\n",
    "    prompt = f\"\"\"\n",
    "Write a valid HTML (no markdown fences) Jinja2 template using TailwindCSS and HTMX\n",
    "for models {models}. Requirements:\n",
    "- Use the Tailwind CDN for simplicity.\n",
    "- Each model has a CRUD section with a table and a form.\n",
    "- Forms use hx-post, hx-delete, and hx-get to interact with the FastAPI endpoints on port 8000.\n",
    "- Use hx-target=\"this\" and hx-swap=\"outerHTML\" for inline updates.\n",
    "- Wrap each section in a <div id=\"{{ model_name|lower }}\"> so the target exists.\n",
    "- Include a <nav> with links to each model section.\n",
    "- Handle HTMX errors gracefully with hx-on::error to show an alert.\n",
    "\"\"\"\n",
    "    html = ask(prompt, model)\n",
    "    Path(\"generated/templates/index.html\").write_text(html)\n",
    "    print(\"Saved generated/templates/index.html\")\n",
    "    \n",
    "def count_code_lines():\n",
    "    total_lines = 0\n",
    "    files = [\"generated/schema.py\", \n",
    "             \"generated/api.py\", \n",
    "             \"generated/frontend.py\",\n",
    "             \"generated/templates/index.html\"]\n",
    "    for file in files:\n",
    "        try:\n",
    "            with open(file, \"r\", encoding=\"utf-8\") as f:\n",
    "                line_count = sum(1 for _ in f)\n",
    "            #print(f\"{file}: {line_count} lines\")\n",
    "            total_lines += line_count\n",
    "        except FileNotFoundError:\n",
    "            print(f\"{file}: File not found.\")\n",
    "    return total_lines\n",
    "\n",
    "# -------------------------------\n",
    "# Step 8: Main orchestration\n",
    "# -------------------------------\n",
    "def main():\n",
    "    user_prompt = input(\"Describe your app: \")\n",
    "    model_choice = input(\"Which model to use? (default: gpt-4o-mini): \") or \"gpt-4o-mini\"\n",
    "\n",
    "    total_tokens = 0\n",
    "    total_cost = 0.0\n",
    "    total_start = time.time()\n",
    "\n",
    "    Path(\"generated\").mkdir(exist_ok=True)\n",
    "    Path(\"generated/__init__.py\").touch(exist_ok=True)\n",
    "\n",
    "    # Step 1\n",
    "    analysis = analyze_prompt(user_prompt, model_choice)\n",
    "    total_tokens += getattr(analysis, \"tokens\", 0) if hasattr(analysis, \"tokens\") else 0\n",
    "\n",
    "    # Step 2\n",
    "    generate_schema(analysis, model_choice)\n",
    "    models = extract_model_names()\n",
    "\n",
    "    # Step 3\n",
    "    generate_api()\n",
    "    generate_frontend(models, model_choice)\n",
    "    generate_index_html(models, model_choice)\n",
    "\n",
    "    total_end = time.time()\n",
    "    total_time = total_end - total_start\n",
    "    code_lines = count_code_lines()\n",
    "\n",
    "    print(\"\\n================================================================\")\n",
    "    print(\"RUN SUMMARY\")\n",
    "    print(f\"Model: {model_choice}\")\n",
    "    print(f\"Input Prompt: {user_prompt}\")\n",
    "    print(f\"Total tokens used: {TOTAL_TOKENS:,}\")\n",
    "    print(f\"Estimated total cost: ${TOTAL_COST:.5f}\")\n",
    "    print(f\"Total runtime: {total_time:.2f} seconds\")\n",
    "    print(f\"Lines of code generated: {code_lines}\")\n",
    "    print(\"==================================================================\\n\")\n",
    "    print(\"\\nExecution Instructions:\")\n",
    "    print(\"Run backend:  uvicorn generated.api:app --reload --port 8000\")\n",
    "    print(\"Run frontend: uvicorn generated.frontend:app --reload --port 8001\")\n",
    "    print(\"Then open http://127.0.0.1:8001 \")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16c8eb9-2d3e-4d80-a874-8708a3f240eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
